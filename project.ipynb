{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header Files\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from csv import DictReader\n",
    "from efficient_apriori import apriori as eff_app\n",
    "import ast\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from mlxtend.frequent_patterns import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.  Data Preprocessing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kaggle DataSet \n",
    "trainRecipe = []\n",
    "included_cols = [1, 10]\n",
    "count = 100000\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "with open('C:/Users/Mayank/Documents/Project/RAW_recipes.csv', encoding=\"utf8\") as f:\n",
    "    read =csv.reader(f)\n",
    "    header = next(read)\n",
    "    for r in read:            \n",
    "        recipe = list(r[i] for i in included_cols)\n",
    "        #print(type(recipe[1])) '<class>, str'        \n",
    "        ingr = ast.literal_eval(recipe[1])\n",
    "        ingrStem = [' '.join(stem_tokens(tokenize(w))) for w in ingr]\n",
    "        trainRecipe.append(ingrStem)\n",
    "        count -= 1\n",
    "        if(count == 0):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Apriori ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsets, rules = eff_app(trainRecipe, min_support=0.2,  min_confidence=1)\n",
    "print((itemsets))\n",
    "print(\"Rules =>\", rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trainRecipe+training_set))\n",
    "comb = trainRecipe+training_set\n",
    "print(comb[99998:100005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "c = Counter(chain.from_iterable(comb)).most_common()[:-30-1:-1]\n",
    "print(\"c = \",c)\n",
    "\n",
    "te = TransactionEncoder()\n",
    "\n",
    "te_ary = te.fit(comb).transform(comb)\n",
    "\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "#print((df.columns))\n",
    "cls2 = apriori(df, min_support=0.1, use_colnames = True)\n",
    "#print((cls2))\n",
    "#print(df)\n",
    "#print(df[cls2['itemsets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens):\n",
    "    stemmed_items = []\n",
    "    for items in tokens:\n",
    "        stemmed_items.append(lemmatizer.lemmatize(items))\n",
    "    return stemmed_items\n",
    "\n",
    "def tokenize(text):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens)\n",
    "    return stems\n",
    "\n",
    "import nltk\n",
    "str1 = \"ziplock bags\"  \n",
    "tok = tokenize(str1)\n",
    "print(' '.join(stem_tokens(tok)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(docs):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    nrows = len(docs)\n",
    "    idx = {}\n",
    "    tid = 0\n",
    "    nnz = 0\n",
    "    for d in docs:\n",
    "        nnz += len(set(d))\n",
    "        for w in d:\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    ncols = len(idx)\n",
    "        \n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    \n",
    "    return mat, idx\n",
    "\n",
    "def csr_info(mat, name=\"\", non_empy=False):\n",
    "    r\"\"\" Print out info about this CSR matrix. If non_empy, \n",
    "    report number of non-empty rows and cols as well\n",
    "    \"\"\"\n",
    "    if non_empy:\n",
    "        print(\"%s [nrows %d (%d non-empty), ncols %d (%d non-empty), nnz %d]\" % (\n",
    "                name, mat.shape[0], \n",
    "                sum(1 if mat.indptr[i+1] > mat.indptr[i] else 0 \n",
    "                for i in range(mat.shape[0])), \n",
    "                mat.shape[1], len(np.unique(mat.indices)), \n",
    "                len(mat.data)))\n",
    "    else:\n",
    "        print( \"%s [nrows %d, ncols %d, nnz %d]\" % (name, \n",
    "                mat.shape[0], mat.shape[1], len(mat.data)) )\n",
    "\n",
    "def csr_l2normalize(mat, copy=False, **kargs):\n",
    "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm. \n",
    "    If copy is True, returns a copy of the normalized matrix.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # normalize\n",
    "    for i in range(nrows):\n",
    "        rsum = 0.0    \n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            rsum += val[j]**2\n",
    "        if rsum == 0.0:\n",
    "            continue  # do not normalize empty rows\n",
    "        rsum = 1.0/np.sqrt(rsum)\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            val[j] *= rsum\n",
    "            \n",
    "    if copy is True:\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90448\n",
      "                                                                             title  \\\n",
      "05zEpbSqcs9E0rcnCJWyZ9OgdH0MLby                                  Christmas Eggnog    \n",
      "mF5SZmoqxF4WtIlhLRvzuKk.z6s7P2S                  Veal, Carrot and Chestnut Ragoût    \n",
      "oQV5D7cVbCFwmrDs3pBUv2y.AG0WV26  Caramelized Bread Pudding with Chocolate and C...   \n",
      "Z9seBJWaB5NkSp4DQHDnCAUBTwov/1u      Sherried Stilton and Green Peppercorn Spread    \n",
      "bB3GxoAplVZeoX3fzWNWyeECtQFxw6G                        Almond-Chocolate Macaroons    \n",
      "FHQAJvovVtPyKWlzgFEHgSUJsCM2Tjq                     White Sauce or Bechamel Sauce    \n",
      "Jt7RKsNPY7/1QrOjuPEomP/s6mD2AvO  Grilled Whole Mackerel with Lemon, Oregano, an...   \n",
      "1rBWKEw7vZjXA97NmHGS3VHq1iVX9c.                                   Apricot Chutney    \n",
      "agTMHTysNlAOyMM3zQlXVu4qbJrLmqa                                   Garlic Croutons    \n",
      "Y..dFCvcwNW4gdogZ3DqLUETR2x.uA2                           Christmas Croquembouche    \n",
      "wAybSELYww/.RDBrZyskjgx0XueW1Mq                        Chocolate Roll-Out Cookies    \n",
      "JnAmtoxgN/vW8NPycwzFW/bCYQH0vXO                                       Mocha Sauce    \n",
      ".iwUfWzkQDtbd5uTDvXyM4A4oluMBCO                 Chocolate Chunk and Pecan Cookies    \n",
      "2RAoUiVRmYrenvEQU2RKVZWJ9Xmxmo6                            Cumin-Chipotle Ketchup    \n",
      "tZyoBQtCH9yXlhi6P5MvIizmh0Eb62a                                       Bobby Burns    \n",
      "z26qlU48ZmhyEvus3NzvTn1vEmjq8Kq                 Sauteed New Potatoes with Parsley    \n",
      "F90CEW4q0ddU7FarDR7WMsqupZ0FV0S                   Caramelized-Apple and Pecan Pie    \n",
      "AcKTUX.eKHroYkKa3qpDQKTzrTqSGdG                      Panettone with Candied Fruit    \n",
      "8GxEhUS4Eom2nDziT7bwq95jlIIKbFO        Bulgur Veggie Burgers with Lime Mayonnaise    \n",
      "4iFC4rMMmwoUzRcMPdWlCiHwNZjlqXu       Peanut Butter and White Chocolate Cream Pie    \n",
      "lSGw36jAaKzy0keFcuR0/VGHzLU3Bya                                 Trout in Riesling    \n",
      "AfmDjxEO2JmKPlVSxoiNnnPPnFijMGW                                     Lobster Stock    \n",
      "al7MiUkzHgNVuJ4F8KOFoFV9b7YxYIC                                Potato Basil Purée    \n",
      "L9w.rdGaaZkQul8xrIceNPFy8Pa08KO   Grilled Sardine Tartines with Onion and Arugula    \n",
      "QZETPtmRHncmATglMlQWH7ah0vLvJQm              Avocado Toast with Tomato-Corn Salsa    \n",
      "0UTBFcok1o1cX9Jwq0I8V/724GOxfxO                                            Labneh    \n",
      "wVFEklKHzz1DGDbLarXJ.qKy9OXxbLu           Pan-Seared Fish Fillets in Ginger Broth    \n",
      "DfUB0AB0N/rVkM/t29Fsoq9Hhmy1NGq        Pancetta and Taleggio Lasagna with Treviso    \n",
      "zwTm5Cma5WEL.ZTFDYsp2gVlk1oyKHO               Mango, Mint, and Pineapple Smoothie    \n",
      "1GW9hHi9W3xTy0w825dfvfWxpyOZYVG             Bourbon and Brown Sugar Glazed Turkey    \n",
      "...                                                                            ...   \n",
      "1C4hHm2UPYah5hHeUnEXs2hVZwy6fZO                            Cherry-Apricot Cobbler    \n",
      "HrzOBHNF7E/1EgrwxNGW3xzrSyX3Lx.                               Ginger-Sesame Sauce    \n",
      "9LDt8uVMiXVomWgMLNcN9FIHd19A4hK   Chicken Breasts with Horseradish-Scallion Crust    \n",
      "zvCFwSAFVLuJ8koOEIFDZLwdhRa9Mwa                 Pork Tenderloin with Plum Chutney    \n",
      "ojZf5JBgMZyk6L.SnFjt01Cwy3ZzcAy  Tomato Soup with Poached Eggs and Crispy Crout...   \n",
      "EkUW1L6L/74XaUCZrJRiNrK02iS6KDq                                   Bloody Mary III    \n",
      "kgkTmQezuJqiulW0oVBXw6cbLmni9Bu                          Tare (Soy Basting Sauce)    \n",
      "uvSUo6dpn5FL3QyaTwxAyE.q4mQTeaW  Warm Chicken Sandwiches with Mushrooms, Spinac...   \n",
      "ZH4uGyPoPaALQlmR1ImAQ7hrpXLWzYq                      Bay Scallop and Corn Chowder    \n",
      "geX9.42HoOCbmBSD36vZok2OodHZ6/C  Roasted Red Pepper, Pepper Jack, and Pepperoni...   \n",
      "tU0r2RYPLP2RX1rD/NL/5eGel.6Ovn6                    Vanilla CreamFilled Doughnuts    \n",
      "tqgIr3hOGBvEjCgbkhcHt41WLmCht2K                       Garlic-Herb Mashed Potatoes    \n",
      "n2bMeuEdtcHXzVSNtyfXIXwop1nN2S6  Pumpkin Cheesecake with Bourbon Sour Cream Top...   \n",
      "X.0yHQNQQ5nnqhEQHWh4rAcYAPkpo.q  Seared Tuna Burgers with Ginger-Garlic Mayonna...   \n",
      "NA2Ituma.40npYkCGKjQar1okgEWTPS         Glazed Pork Loin with Cilantro and Garlic    \n",
      "U7yTvlxEVHO9.GDWcrwtHIyCiXpv2A2             Grilled Brined Shrimp with Garlic Oil    \n",
      "//jNtifOb4nO1bc3gMe1ea7xFH4nz5m                                Lima-Bean Crostini    \n",
      "WGwt2Dp2UVVaBsIj6C9Yv2AD76Zmc2G                                   Lemon Ice Cream    \n",
      "25XcQPfB7soB86qACg.9T5smks3I5cC                           Chocolate Bread Pudding    \n",
      "nUgYjdVaWvQLvgSi7U9aH16WfdlmoMa               Spicy Eggplant and Green Bean Curry    \n",
      "VUfq3eH/dAQ2DDaa83Dp1x8Hdm7vCv6   Grilled Clam Toasts With Lemon and Green Olives    \n",
      "g0paH27SGSQ/aN.el/wwu/nxX7RnmIi                              Pear and Almond Tart    \n",
      "ARu0StlTkUfsW5DKqtmupUEJyF8Rdh6                    Tropical Fruit and Cake Trifle    \n",
      "cbKR3qnmLFpQTNxrF7qYhy1kEaXJ6w.                            Brandied Caramel Sauce    \n",
      "K0hj3K9zJA3.WqLpYyijMgCYZ7dSQOu                                      Festive Nuts    \n",
      "lgygAJbdT1RNgrOYYveXtW4Ze9GtcZK                           Spinach and Lentil Soup    \n",
      "EgIvlp1EfF4qTsnSI3v7ViZF1b3f2qC                         Fresh Cheese with Spinach    \n",
      "aCaoP.P8A1h6ALQmBnw3ypvYfRt/zZe     Jalapeño and Lime–Marinated Skirt Steak Tacos    \n",
      "fGxd/ZNUQcXxxqaVgEtMJmsNKLbugAe                        Semolina–Lemon Syrup Cakes    \n",
      "qznqHiNpq0AB1AYn002A2HvaEFnN0lq                                Chicken Cacciatore    \n",
      "\n",
      "                                                                       ingredients  \n",
      "05zEpbSqcs9E0rcnCJWyZ9OgdH0MLby  [12 egg whites, 12 egg yolks, 1 1/2 cups sugar...  \n",
      "mF5SZmoqxF4WtIlhLRvzuKk.z6s7P2S  [18 fresh chestnuts, 2 1/2 pounds veal stew me...  \n",
      "oQV5D7cVbCFwmrDs3pBUv2y.AG0WV26  [2 tablespoons unsalted butter, softened, 4 or...  \n",
      "Z9seBJWaB5NkSp4DQHDnCAUBTwov/1u  [3/4 pound Stilton, crumbled (about 3 cups) an...  \n",
      "bB3GxoAplVZeoX3fzWNWyeECtQFxw6G  [2 cups (about 9 1/2 ounces) whole almonds, to...  \n",
      "FHQAJvovVtPyKWlzgFEHgSUJsCM2Tjq  [2 tablespoons butter, 2 tablespoons flour, 1 ...  \n",
      "Jt7RKsNPY7/1QrOjuPEomP/s6mD2AvO  [1/2 teaspoon finely grated fresh lemon zest, ...  \n",
      "1rBWKEw7vZjXA97NmHGS3VHq1iVX9c.  [2 garlic cloves, finely chopped, 2 teaspoons ...  \n",
      "agTMHTysNlAOyMM3zQlXVu4qbJrLmqa  [2 tablespoons (1/4 stick) butter, 1/4 cup oli...  \n",
      "Y..dFCvcwNW4gdogZ3DqLUETR2x.uA2  [1 recipe pâte à chou, About 1 cup pastry crea...  \n",
      "wAybSELYww/.RDBrZyskjgx0XueW1Mq  [2 1/2 cups all purpose flour, 1/4 cup unsweet...  \n",
      "JnAmtoxgN/vW8NPycwzFW/bCYQH0vXO  [2 tablespoons brewed coffee, 1 ounce semiswee...  \n",
      ".iwUfWzkQDtbd5uTDvXyM4A4oluMBCO  [1 cup all purpose flour, 1/2 teaspoon ground ...  \n",
      "2RAoUiVRmYrenvEQU2RKVZWJ9Xmxmo6  [1 1/2 teaspoons cumin seeds, 3/4 cup ketchup,...  \n",
      "tZyoBQtCH9yXlhi6P5MvIizmh0Eb62a  [1 ounce Scotch whiskey, 1/2 ounce sweet vermo...  \n",
      "z26qlU48ZmhyEvus3NzvTn1vEmjq8Kq  [16 baby red-skinned potatoes (about 1 1/4 pou...  \n",
      "F90CEW4q0ddU7FarDR7WMsqupZ0FV0S  [2 cups all purpose flour, 1 tablespoon sugar,...  \n",
      "AcKTUX.eKHroYkKa3qpDQKTzrTqSGdG  [1/4 teaspoon sugar, 1 teaspoon active dry yea...  \n",
      "8GxEhUS4Eom2nDziT7bwq95jlIIKbFO  [1/2 cup chopped onion, divided, 1 tablespoon ...  \n",
      "4iFC4rMMmwoUzRcMPdWlCiHwNZjlqXu  [1 cup sifted powdered sugar, 3/4 cup smooth o...  \n",
      "lSGw36jAaKzy0keFcuR0/VGHzLU3Bya  [2 tablespoons (1 oz) unsalted butter plus add...  \n",
      "AfmDjxEO2JmKPlVSxoiNnnPPnFijMGW  [3 tablespoons corn oil, 1 pound cleaned, unco...  \n",
      "al7MiUkzHgNVuJ4F8KOFoFV9b7YxYIC  [2 cups fresh basil leaves, lightly packed, 2 ...  \n",
      "L9w.rdGaaZkQul8xrIceNPFy8Pa08KO  [12 butterflied fresh sardines or six 6-inch-l...  \n",
      "QZETPtmRHncmATglMlQWH7ah0vLvJQm  [3 plum tomatoes, diced, 2 scallions, trimmed,...  \n",
      "0UTBFcok1o1cX9Jwq0I8V/724GOxfxO  [Olive oil, Spices (we're suckers for za'atar)...  \n",
      "wVFEklKHzz1DGDbLarXJ.qKy9OXxbLu  [1/4 lb Shanghai bok choy (about 3 small heads...  \n",
      "DfUB0AB0N/rVkM/t29Fsoq9Hhmy1NGq  [3 tablespoons extra-virgin olive oil, 8 ounce...  \n",
      "zwTm5Cma5WEL.ZTFDYsp2gVlk1oyKHO  [1/2 cup chopped mango, 1/2 cup chopped pineap...  \n",
      "1GW9hHi9W3xTy0w825dfvfWxpyOZYVG  [6 tablespoons kosher salt, 4 tablespoons blac...  \n",
      "...                                                                            ...  \n",
      "1C4hHm2UPYah5hHeUnEXs2hVZwy6fZO  [Butter, 3 14.5-ounce cans pitted tart cherrie...  \n",
      "HrzOBHNF7E/1EgrwxNGW3xzrSyX3Lx.  [1/2 cup mayonnaise, 2 tablespoons seasoned ri...  \n",
      "9LDt8uVMiXVomWgMLNcN9FIHd19A4hK  [1 1/2 teaspoons Dijon mustard, 1/4 cup mayonn...  \n",
      "zvCFwSAFVLuJ8koOEIFDZLwdhRa9Mwa  [4 red or black plums, 1 tablespoon olive oil,...  \n",
      "ojZf5JBgMZyk6L.SnFjt01Cwy3ZzcAy  [3 tablespoons extra-virgin olive oil, 2 cups ...  \n",
      "EkUW1L6L/74XaUCZrJRiNrK02iS6KDq  [1 ounce (2 tablespoons) vodka, 2/3 cup tomato...  \n",
      "kgkTmQezuJqiulW0oVBXw6cbLmni9Bu  [1/2 cup low-salt chicken broth, 1/4 cup mirin...  \n",
      "uvSUo6dpn5FL3QyaTwxAyE.q4mQTeaW  [4 ciabatta rolls, halved horizontally, 3 tabl...  \n",
      "ZH4uGyPoPaALQlmR1ImAQ7hrpXLWzYq  [3 ears corn (fresh or frozen), kernels cut fr...  \n",
      "geX9.42HoOCbmBSD36vZok2OodHZ6/C  [1 round loaf sourdough bread (about 7 inches ...  \n",
      "tU0r2RYPLP2RX1rD/NL/5eGel.6Ovn6  [1 package (2 1/2 teaspoons) active dry yeast ...  \n",
      "tqgIr3hOGBvEjCgbkhcHt41WLmCht2K  [1 pound red potatoes (peeled if desired), cut...  \n",
      "n2bMeuEdtcHXzVSNtyfXIXwop1nN2S6  [3/4 cup graham cracker crumbs, 1/2 cup finely...  \n",
      "X.0yHQNQQ5nnqhEQHWh4rAcYAPkpo.q  [2 3/4-inch-thick tuna steaks (each about 5 to...  \n",
      "NA2Ituma.40npYkCGKjQar1okgEWTPS  [1 teaspoon crushed hot red pepper flakes, 1 t...  \n",
      "U7yTvlxEVHO9.GDWcrwtHIyCiXpv2A2  [8 cups ice water, divided, 1/3 cup coarse kos...  \n",
      "//jNtifOb4nO1bc3gMe1ea7xFH4nz5m  [1 (1-pound) box frozen lima beans, 2 cups ext...  \n",
      "WGwt2Dp2UVVaBsIj6C9Yv2AD76Zmc2G  [1 large lemon, 1 cup sugar, 1 cup milk, 1 cup...  \n",
      "25XcQPfB7soB86qACg.9T5smks3I5cC  [2 cups milk, 3 ounces unsweetened chocolate, ...  \n",
      "nUgYjdVaWvQLvgSi7U9aH16WfdlmoMa  [5 tablespoons vegetable oil, divided, 4 garli...  \n",
      "VUfq3eH/dAQ2DDaa83Dp1x8Hdm7vCv6  [1 lemon, 4 pounds littleneck clams, 1 garlic ...  \n",
      "g0paH27SGSQ/aN.el/wwu/nxX7RnmIi  [2 large egg yolks, 2 tablespoons apple cider,...  \n",
      "ARu0StlTkUfsW5DKqtmupUEJyF8Rdh6  [1 package (3.4 ounces) vanilla pudding, Veget...  \n",
      "cbKR3qnmLFpQTNxrF7qYhy1kEaXJ6w.  [2 cups sugar, 2/3 cup plus 1/4 cup water, 1/2...  \n",
      "K0hj3K9zJA3.WqLpYyijMgCYZ7dSQOu  [1/2 cup sugar, 1/2 teaspoon each: ground clov...  \n",
      "lgygAJbdT1RNgrOYYveXtW4Ze9GtcZK  [5 cups (about) canned beef broth, 1 cup lenti...  \n",
      "EgIvlp1EfF4qTsnSI3v7ViZF1b3f2qC  [1/2 teaspoon turmeric, 2 cups water, 3/4 poun...  \n",
      "aCaoP.P8A1h6ALQmBnw3ypvYfRt/zZe  [1 medium jalapeño, thinly sliced, 2 garlic cl...  \n",
      "fGxd/ZNUQcXxxqaVgEtMJmsNKLbugAe  [1 1/2 cups almond flour or almond meal, 1/2 c...  \n",
      "qznqHiNpq0AB1AYn002A2HvaEFnN0lq  [1 1/2 pounds plum tomatoes, coarsely chopped ...  \n",
      "\n",
      "[25323 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Using dataset from https://eightportions.com/datasets/Recipes/\n",
    "#Contains recipe name and list of ingredients used\n",
    "data1 = pd.read_json('data/recipes_raw_nosource_ar.json', orient = 'index')\n",
    "recipeIg1 = data1['ingredients']\n",
    "len1 = len(recipeIg1)\n",
    "\n",
    "data2 = pd.read_json('data/recipes_raw_nosource_epi.json', orient = 'index')\n",
    "recipeIg2 = data2[['title','ingredients']]\n",
    "len2 = len(recipeIg2)\n",
    "\n",
    "data3 = pd.read_json('data/recipes_raw_nosource_fn.json', orient = 'index')\n",
    "recipeIg3 = data2[['title','ingredients']]\n",
    "len3 = len(recipeIg3)\n",
    "\n",
    "print(len1+len2+len3)\n",
    "print(recipeIg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data URL: https://www.kaggle.com/kaggle/recipe-ingredients-dataset(Data set with cuisines)\n",
    "\n",
    "# Create URL to JSON file (alternatively this can be a filepath)\n",
    "url = 'C:/Users/Mayank/Documents/Project/train.json'\n",
    "\n",
    "# Load the first sheet of the JSON file into a data frame\n",
    "df = pd.read_json(url, orient='columns')\n",
    "\n",
    "ingredients_1 = df['ingredients']\n",
    "# View the first ten rows\n",
    "train_list = ingredients_1.values.tolist()\n",
    "print(train_list[0:10])\n",
    "print(ingredients_1.head(10))\n",
    "len(ingredients_1)\n",
    "training_set = []\n",
    "for ingr in ingredients_1:\n",
    "    ingrStem = [' '.join(stem_tokens(tokenize(w))) for w in ingr]\n",
    "    training_set.append(ingrStem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(train_list).transform(train_list)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "#print((df.columns))\n",
    "cls2 = apriori(df, min_support=0.1, use_colnames = True)\n",
    "print((cls2))\n",
    "#print(df)\n",
    "#print(df[cls2['itemsets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data URL: https://www.kaggle.com/hugodarwood/epirecipes\n",
    "\n",
    "# Create URL to JSON file (alternatively this can be a filepath)\n",
    "url = 'full_format_recipes.json'\n",
    "\n",
    "# Load the first sheet of the JSON file into a data frame\n",
    "df = pd.read_json(url, orient='columns')\n",
    "\n",
    "ingredients_2 = df[['title','ingredients']]\n",
    "# View the first ten rows\n",
    "print(ingredients_2.head(10))\n",
    "print(len(ingredients_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "with np.load('C:/Users/Mayank/Documents/Project/simplified-recipes-1M.npz') as data:\n",
    "    recipes = data['recipes']\n",
    "    ingredients = data['ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingrlist = []\n",
    "counter = 0\n",
    "for recipe in recipes:\n",
    "    if(recipe.size) == 0:\n",
    "        continue\n",
    "    ingrlist.append(ingredients[recipe])\n",
    "    counter += 1\n",
    "    #break\n",
    "\n",
    "print(counter)\n",
    "#ingredients[recipes[0]]\n",
    "#print(ingrlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(ingrlist).transform(ingrlist)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "#print((df.columns))\n",
    "cls2 = apriori(df, min_support=0.2, use_colnames = True)\n",
    "print((cls2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsets, rules = eff_app(ingrlist, min_support=0.08,  min_confidence=0.3)\n",
    "print((itemsets))\n",
    "print(\"Rules =>\", rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
